{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribution: Elena, with discussion with Shashank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes's Theorem: \n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu, \\sigma \\mid D, I) = \\frac{P(D \\mid \\mu,\\sigma, I)\\,P(\\mu, \\sigma \\mid I)}{P(D \\mid I)}\n",
    "\\end{align}\n",
    "\n",
    "where $D = \\{(\\mu_1, \\sigma_1), (\\mu_2, \\sigma_2)\\}$.\n",
    "\n",
    "We assume that the measured values of $\\mu_1$ and $\\mu_2$ are Gaussian distributed with variances $\\sigma_1^2$ and $\\sigma_2^2$. Thus, we can write our likelihood with a Gaussian form:\n",
    "\n",
    "\\begin{align}\n",
    "P(D \\mid \\mu, \\sigma, I) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left[-\\frac{1}{2\\sigma^2}\\sum_{i\\in D}(\\mu_i - \\mu)^2\\right]\n",
    "\\end{align}\n",
    "\n",
    "We choose a uniform prior for $\\mu$ and a Jeffreys prior for $\\sigma$. The posterior is then: \n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu, \\sigma \\mid D, I) &\\propto\\frac{1}{\\sigma^{n+1}}\n",
    "\\exp\\left[-\\frac{1}{2\\sigma^2}\\sum_{i\\in D}(\\mu_i - \\mu)^2\\right]\n",
    "\\end{align}\n",
    "\n",
    "We can marginalize the posterior over $\\sigma$, giving a Student-t distribution.\n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu \\mid D,I) &\\propto \\left(1 + \\frac{(\\mu - \\bar{\\mu})^2}{r^2}\\right)^{-\\frac{n}{2}};\\\\\n",
    "r^2 &= \\frac{1}{n}\\sum_{\\mu_i\\in D}(\\mu_i - \\bar{\\mu})^2; \\\\\n",
    "\\bar{\\mu} &= \\frac{1}{n}\\sum_{\\mu_i\\in D}\\mu_i,\n",
    "\\end{align}\n",
    "\n",
    "where $n = |D|$ is the number of data in $D$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that the most probable value for $\\mu$ will simply be the mean of $\\mu_1$ and $\\mu_2$. \n",
    "\n",
    "Now, our group can imagine two ways to calculate the error bar for $\\mu$. The first way is to approximate the posterior\n",
    "distribution as Gaussian and report intervals based on the standard deviation of the Gaussian approximation. As seen in lecture 2, if we expand the logarithm of the posterior probability distribution function in a Taylor series to the second order about its maximum, exponentiate, and evaluate the normalization constant, we will get:\n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu \\mid D, I) \\approx \\frac{1}{\\sqrt{2\\pi r^2/n}}\\exp\\left[-\\frac{(\\mu - \\bar{\\mu})^2}{2r^2/n}\\right]\n",
    "\\end{align}\n",
    "\n",
    "The error bar will be $\\frac{r}{\\sqrt{n}}$, which is $\\frac{1}{\\sqrt{n}}\\left(\\frac{\\sqrt{(\\mu_1 - \\bar{\\mu})^2 + (\\mu_2 - \\bar{\\mu})^2}}{\\sqrt{n}}\\right)$. This simplifies to $\\frac{\\sqrt{(\\mu_1 - \\bar{\\mu})^2 + (\\mu_2 - \\bar{\\mu})^2}}{n}$ or $\\frac{\\sqrt{(\\mu_1 - \\bar{\\mu})^2 + (\\mu_2 - \\bar{\\mu})^2}}{2}$ since in this case, $n = 2$.\n",
    "\n",
    "The other way we imagine to calculate an error bar would be to apply the rules for error propagation to $\\sigma_1$ and $\\sigma_2$. We already found that the most probable value for $\\mu$ is $\\frac{\\mu_1 \\, + \\, \\mu_2}{2}$, so to get $\\sigma$ for $\\mu$, we add $\\sigma_1$ and $\\sigma_2$ in quadrature, then divide by 2: $\\sigma = \\frac{\\sqrt{\\sigma_1^2 \\, + \\, \\sigma_2^2}}{2}$.\n",
    "\n",
    "Both ways of calculating the error bar have a very similar form. However, they are not necessarily equivalent as (at least without being given more information), we do not think we can assume $\\sigma_1 = \\mu_1 - \\bar{\\mu}$ or $\\sigma_2 = \\mu_2 - \\bar{\\mu}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
