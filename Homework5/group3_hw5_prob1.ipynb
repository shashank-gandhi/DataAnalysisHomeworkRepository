{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5.1\n",
    "Attributions: Shashank did a,b, and c; Michelle did d; Elena did e; Elena and Shashank did f.\n",
    "\n",
    "Before we do anything else, we load the necessary modules and read in the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Our numerical workhorses\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "\n",
    "# Import plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import stat tools\n",
    "import numdifftools as ndt\n",
    "import scipy.stats as st\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables high res graphics inline (only use with static plots (non-Bokeh))\n",
    "# SVG is preferred, but there is a bug in Jupyter with vertical lines\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# JB's favorite Seaborn settings for notebooks\n",
    "rc = {'lines.linewidth': 2, \n",
    "      'axes.labelsize': 18, \n",
    "      'axes.titlesize': 18, \n",
    "      'axes.facecolor': 'DFDFE5'}\n",
    "sns.set_context('notebook', rc=rc)\n",
    "sns.set_style('darkgrid', rc=rc)\n",
    "\n",
    "# Suppress future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('./data/mean_rest_bouts.csv', comment='#')\n",
    "\n",
    "# Pull out wild type and mutant and take NaNs to be zero\n",
    "df = df[df['genotype'].isin(['wt', 'mut'])].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "Sample mean is the best estimate of $\\mu$. Unbiased estimator of variance is:\n",
    "\\begin{align}\n",
    "\\frac{n}{n-1}&s^2\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_estimates(data):\n",
    "    \"\"\"\n",
    "    Takes a tody dataframe as an input. Returns:\n",
    "    1. mu_wt\n",
    "    2. mu_mut\n",
    "    3. sigma_wt\n",
    "    4. sigma_mut\n",
    "    \"\"\"\n",
    "    #separate the dataset in to wild type and mutant\n",
    "    wt_fish = data[data[\"genotype\"]==\"wt\"]\n",
    "    mut_fish = data[data[\"genotype\"]==\"mut\"]\n",
    "\n",
    "    #find means for wt and mut\n",
    "    mu_wt = wt_fish.mean()\n",
    "    mu_mut = mut_fish.mean()\n",
    "\n",
    "    #find unbiased estimator of variance for wt and mut\n",
    "    sigma_wt = np.sqrt(wt_fish.var(ddof=1))\n",
    "    sigma_mut = np.sqrt(mut_fish.var(ddof=1))\n",
    "\n",
    "    #return values\n",
    "    return float(mu_wt), float(mu_mut), float(sigma_wt), float(sigma_mut)\n",
    "\n",
    "#part a\n",
    "\n",
    "muWT, muMUT, sigmaWT, sigmaMUT = get_estimates(df)\n",
    "\n",
    "print(\"\"\"The best estimates for µ and σ are:\n",
    "                µ           σ\n",
    "             -----------------\n",
    "    WT       {0:.4f}     {2:.4f}\n",
    "    Mutant   {1:.4f}     {3:.4f}\n",
    "    \"\"\".format(float(muWT), float(muMUT), \n",
    "           float(sigmaWT), float(sigmaMUT)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cohen_d(data):\n",
    "    \"\"\"\n",
    "    Cohen's d\n",
    "    \"\"\"\n",
    "    #separate the dataset in to wild type and mutant\n",
    "    w = data[data[\"genotype\"]==\"wt\"]\n",
    "    m = data[data[\"genotype\"]==\"mut\"]\n",
    "    \n",
    "    w_s = w.var(ddof=1)\n",
    "    m_s = m.var(ddof=1)\n",
    "    \n",
    "    sd = ((len(w)-1) * w_s + (len(m) - 1) * m_s) / (len(w) + len(m) - 2)\n",
    "    \n",
    "    diff = m.mean() - w.mean()\n",
    "\n",
    "    cohen = np.abs(diff) / np.sqrt(sd)\n",
    "    \n",
    "    return float(cohen)\n",
    "\n",
    "effect_size = cohen_d(df)\n",
    "\n",
    "print ('Effect size = {0:.4f}'.format(effect_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequentist estimate of the difference of the means:\n",
    "\\begin{align}\n",
    "\\delta \\equiv \\mu_{wt} - \\mu_{mut}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_frequentist_estimate(mu_wt, sigma_wt, mu_mut, sigma_mut, data, trials=10000):\n",
    "    \"\"\"\n",
    "    Returns frequentist estimate of the difference of the mean with a 95%\n",
    "    confidence interval. Takes as input the result of get_estimates \n",
    "    function defined in part a.\n",
    "    \"\"\"\n",
    "   \n",
    "    #separate the dataset in to wild type and mutant\n",
    "    wt_fish = data[data[\"genotype\"]==\"wt\"]\n",
    "    mut_fish = data[data[\"genotype\"]==\"mut\"]\n",
    "    \n",
    "    def difference_of_means(mu_wt, sigma_wt, mu_mut, sigma_mut, reps_wt, reps_mut, trials):\n",
    "        \"\"\"\n",
    "        This function draws samples out of a gaussian distribution defined for wildtype\n",
    "        and mutant population using means and sigmas calculated in part a.\n",
    "        \"\"\"\n",
    "        difference_mean_holder = np.empty(trials)\n",
    "    \n",
    "        for i in range(trials):\n",
    "            wt_rep_mean = np.random.normal(mu_wt, sigma_wt, reps_wt).mean()\n",
    "            mut_rep_mean = np.random.normal(mu_mut, sigma_mut, reps_mut).mean()\n",
    "            difference_mean_holder[i] = wt_rep_mean - mut_rep_mean\n",
    "        \n",
    "        return difference_mean_holder\n",
    "    \n",
    "    difference_out = difference_of_means(muWT, sigmaWT, muMUT,sigmaMUT, len(wt_fish),len(mut_fish), trials)\n",
    "    \n",
    "    frequentist_lowCI, frequentist_highCI = np.percentile(difference_out, (2.5,97.5))\n",
    "    return float(mu_wt - mu_mut), float(1.96*np.std(difference_out)), float(frequentist_lowCI),\\\n",
    "float(frequentist_highCI)\n",
    "\n",
    "#unpack results\n",
    "frequentist_estimate, confidence_interval, frequentist_lowCI, frequentist_highCI = \\\n",
    "get_frequentist_estimate(muWT, sigmaWT, muMUT, sigmaMUT, df, 10000)\n",
    "\n",
    "print(\"\"\"The frequentist estimate of the difference of the mean is:\n",
    "      µ(wt)-µ(mut) = {0:.4f} ± {1:.4f}\"\"\"\n",
    "      .format(float(frequentist_estimate), confidence_interval), \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_bayesian_estimate(data):\n",
    "    \"\"\"\n",
    "    This function takes the dataframe containing wildtype and mutant fish and\n",
    "    calculates the bayesian estimate for the difference of the means.\n",
    "    \"\"\"\n",
    "    #separate the dataset in to wild type and mutant\n",
    "    wt_fish = data[data[\"genotype\"]==\"wt\"]\n",
    "    mut_fish = data[data[\"genotype\"]==\"mut\"]\n",
    "    \n",
    "    # Define log of the posterior\n",
    "    def log_post(p, x_wt, x_mut):\n",
    "        \"\"\"\n",
    "        Returns the log of the posterior consisting of the product of Gaussians.\n",
    "        p[0] = mu_wt\n",
    "        p[1] = mu_mut\n",
    "        p[2] = sigma_wt\n",
    "        p[3] = sigma_mut\n",
    "        \"\"\"\n",
    "        # Unpack parameters\n",
    "        mu_wt, mu_mut, sigma_wt, sigma_mut = p\n",
    "    \n",
    "        # Make sure we have everything in the right range\n",
    "        if (sigma_wt < 0) or (sigma_mut < 0):\n",
    "            return -np.inf\n",
    "\n",
    "        # Compute separate parts of posterior from each sample\n",
    "        log_post_wt = st.norm.logpdf(x_wt, mu_wt, sigma_wt).sum() - np.log(sigma_wt)\n",
    "    \n",
    "        log_post_mut = st.norm.logpdf(x_mut, mu_mut, sigma_mut).sum() - np.log(sigma_mut)\n",
    "\n",
    "        # Add them up to return\n",
    "        return log_post_wt + log_post_mut\n",
    "\n",
    "    def negative_log_post(p, x_wt, x_mut):\n",
    "        \n",
    "        return -log_post(p, x_wt, x_mut)\n",
    "\n",
    "    #MAP\n",
    "    wt = wt_fish[(\"mean_rest_bout_length\")]\n",
    "    mut = mut_fish[(\"mean_rest_bout_length\")]\n",
    "    \n",
    "    #define args\n",
    "    args = (wt, mut)\n",
    "    p0 = np.array([ 2, 1.5, 0.5, 0.8])\n",
    "\n",
    "    hes_fun = ndt.Hessian(log_post)\n",
    "    res = scipy.optimize.minimize(negative_log_post, p0, args=args)\n",
    "    hes = hes_fun(res.x,wt,mut)\n",
    "    cov = -np.linalg.inv(hes)\n",
    "\n",
    "    bayesian_estimate_diff = res.x[0] - res.x[1]\n",
    "    credible_interval = 1.96 * np.sqrt(np.sqrt(cov[0,0])**2 + np.sqrt(cov[1,1])**2)\n",
    "    \n",
    "    lowCI, highCI = np.percentile(bayesian_estimate_diff, (2.5, 97.5))\n",
    "    \n",
    "    return float(bayesian_estimate_diff), float(credible_interval), cov, float(res.x[0]), float(res.x[1]), \\\n",
    "float(res.x[2]), float(res.x[3]), float(lowCI), float(highCI)\n",
    "\n",
    "bayesian_estimate, credible_interval, covariance, WTmuMAP, MUTmuMAP, WTsigmaMAP, MUTsigmaMAP, \\\n",
    "bayesian_lowCI, bayesian_highCI = get_bayesian_estimate(df)\n",
    "\n",
    "print(\"\"\"The Bayesian estimate of the difference of the mean is:\n",
    "    µ(wt)-µ(mut) = {0:.4f} ± {1:.4f}\"\"\".format(bayesian_estimate, credible_interval), \"minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to test our null hypothesis. $H_0$ is that the wild type and mutant are drawn from the same Gaussian distribution, more specifically a student-t distribution. In other words that the means are the same $\\mu_{wt} = \\mu_{mut}$. \n",
    "\n",
    "We can use a T-statistic as our measurable statistic. \n",
    "\\begin{align}\n",
    "T = \\frac {\\bar{x}_1 - \\bar{x}_2 - n_1 + n_2} {S_D \\sqrt{n^{-1}_1 + n^{-1}_2}}\n",
    "\\end{align}\n",
    "Where $S_D$ is defined as:\n",
    "\\begin{align}\n",
    "S_D = \\frac {(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2} {n_1 + n_2 -2}\n",
    "\\end{align}\n",
    "And $S_1$ and $S_2$ are\n",
    "\\begin{align}\n",
    "S = \\frac {1}{n - 1} \\sum_{i \\in D}{(x_i - \\bar{x})^2}\n",
    "\\end{align}\n",
    "for their respective values.\n",
    "\n",
    "We want to combine all of our measurements and then redistribute them to a group of 17 and group of 22 and we want to do this over and over again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# our null hypothesis is that the mutant and the wild type are drawn from the same\n",
    "# Gaussian distribution in other words we want to test if the mutant mean is the same\n",
    "# as the wt mean\n",
    "\n",
    "# We first combine all of the measurements and then distrbute them to a set of 17 and \n",
    "# a set of 22\n",
    "\n",
    "def final_p_value(data, trials=10000, greater_or_less='greater', return_abs=False):\n",
    "    \n",
    "    #separate the dataset in to wild type and mutant\n",
    "    wt_fish = data[data[\"genotype\"]==\"wt\"]\n",
    "    mut_fish = data[data[\"genotype\"]==\"mut\"]\n",
    "    \n",
    "    # we want to make an array of the mean rest bout lengths\n",
    "    w = wt_fish['mean_rest_bout_length'].values\n",
    "    m = mut_fish['mean_rest_bout_length'].values\n",
    "    \n",
    "    def distribute_samples(w, m, some_func, trials, args=()):\n",
    "        '''\n",
    "        combine our measurements for rest bout and redistribute them to two groups\n",
    "        '''\n",
    "    \n",
    "        # first we create an empty array to store our samples\n",
    "        samples = np.empty(trials)\n",
    "    \n",
    "        # concatenate all the measurements\n",
    "        measurements = np.concatenate((w, m))\n",
    "    \n",
    "        # create sets for all trials \n",
    "        for i in range(trials):\n",
    "            measurements = np.random.permutation(measurements)\n",
    "            samples[i] = some_func(measurements[:len(w)], measurements[len(w):], *args)\n",
    "     \n",
    "        return samples\n",
    "\n",
    "\n",
    "    # now I want to define the p-value\n",
    "    def p_value(samples, actual, greater_or_less='greater'):\n",
    "        '''\n",
    "        compute the p value (the probability our measurement is \n",
    "        greather than or less than the actual value\n",
    "        '''\n",
    "    \n",
    "        if greater_or_less == 'greater':\n",
    "            return float(np.sum(samples >= actual) / len(samples))\n",
    "        else:\n",
    "            return float(np.sum(samples <= actual) / len(samples))\n",
    "\n",
    "    # now we can run our test and see if we will get the actual difference in our means\n",
    "    # this will be my some_func in my distribute_samples function\n",
    "    \n",
    "    def T_stat(w, m, return_abs=False):\n",
    "        '''\n",
    "        Calculate the absolute difference of the means\n",
    "        '''\n",
    "        w_s = w.var(ddof=1)\n",
    "        m_s = m.var(ddof=1)\n",
    "    \n",
    "        sd = ((len(w)-1) * w_s**2 + (len(m) - 1) * m_s**2) / (len(w) + len(m) - 2)\n",
    "    \n",
    "        diff = w.mean() - m.mean() - np.sqrt(w.var()) + np.sqrt(m.var()) \n",
    "        pool_variance = sd * np.sqrt(1/(len(w)) + 1/(len(m)))\n",
    "            \n",
    "        if return_abs:\n",
    "            return float(np.abs(diff) / pool_variance   )\n",
    "        return float(diff / pool_variance)\n",
    "\n",
    "\n",
    "    # let's retrieve all our random sample sets of two\n",
    "    samples = distribute_samples(w, m, T_stat, trials, args = (True,))\n",
    "\n",
    "    # calculate p value\n",
    "    p_value_student_t = p_value(samples, T_stat(w, m))\n",
    "\n",
    "    return float(p_value_student_t)\n",
    "\n",
    "p_value = final_p_value(df, 10000)\n",
    "\n",
    "print(\"Welch's t test p value =\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def odds_ratio(data, cov, wt_mu_map, wt_sigma_map, mut_mu_map, mut_sigma_map):\n",
    "    \"\"\"\n",
    "    This function calculates the odds ratio for H_0 and H_1.\n",
    "    \n",
    "    data = the dataframe with all of the wt and mut fish\n",
    "    cov = the covariance matrix calculated for the joint Gaussian distribution in part (c)\n",
    "    wt_mu_map = the MAP for the wild-type mu as calculated in part (c)\n",
    "    wt_sigma_map = the MAP for the wild-type sigma as calculated in part (c)\n",
    "    mut_mu_map = the MAP for the mutant mu as calculated in part (c)\n",
    "    mut_sigma_map = the MAP for the mutant sigma as calculated in part (c)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Set up additional variables to pass in as arguments to the sub-functions\n",
    "    wt_fish = data[data['genotype']=='wt']\n",
    "    mut_fish = data[data['genotype']=='mut']\n",
    "    \n",
    "    p = np.asarray([data['mean_rest_bout_length'].mean(), data['mean_rest_bout_length'].std()])\n",
    "    x = data['mean_rest_bout_length']\n",
    "    wt_mut = np.asarray([wt_fish['mean_rest_bout_length'], mut_fish['mean_rest_bout_length']])\n",
    "    \n",
    "    # Define log of the posterior for H_0 \n",
    "    def log_post_H0(p, x):\n",
    "        \"\"\"\n",
    "        Returns the log of the posterior for a Gaussian.\n",
    "        p[0] = mu\n",
    "        p[1] = sigma\n",
    "        \"\"\"\n",
    "        # Unpack parameters\n",
    "        mu, sigma = p\n",
    "    \n",
    "        # Make sure we have everything in the right range\n",
    "        if (sigma < 0):\n",
    "            return -np.inf\n",
    "\n",
    "        # Add them up to return\n",
    "        output = float(st.norm.logpdf(x, mu, sigma).sum() - np.log(sigma))\n",
    "                \n",
    "        return output\n",
    "\n",
    "    def cov_H0(p, x):    \n",
    "        \"\"\"\n",
    "        Calculates the covariance matrix for H_0\n",
    "        \"\"\"\n",
    "        # Instantiate Hessian for log posterior for H_0\n",
    "        hes_fun = ndt.Hessian(log_post_H0)\n",
    "\n",
    "        # Compute Hessian at MAP for H_0\n",
    "        hes = hes_fun(p, x)\n",
    "        cov = -np.linalg.inv(hes)\n",
    "            \n",
    "        return cov\n",
    "\n",
    "    def log_good_fit_ratio(p, x, wt_mut, wt_mu_map, wt_sigma_map, mut_mu_map, mut_sigma_map): \n",
    "        \"\"\"\n",
    "        Calculates the log of the goodness of fit ratio\n",
    "        \"\"\"\n",
    "        # Unpack parameters\n",
    "        mu, sigma = p\n",
    "        \n",
    "        ratio_output = st.norm.logpdf(x, mu, sigma).sum() \\\n",
    "    - st.norm.logpdf(wt_mut[0], wt_mu_map, wt_sigma_map).sum() \\\n",
    "    - st.norm.logpdf(wt_mut[1], mut_mu_map, mut_sigma_map).sum()\n",
    "        \n",
    "        return float(ratio_output)\n",
    "\n",
    "    def log_occam(p, x, wt_sigma_map, mut_sigma_map, cov):\n",
    "        \"\"\"\n",
    "        Calculates the log of the Occam factor\n",
    "        \"\"\"\n",
    "        # Unpack parameters\n",
    "        mu, sigma = p\n",
    "                \n",
    "        return np.log(wt_sigma_map) + np.log(mut_sigma_map) + \\\n",
    "                    np.log(2 * np.pi) + np.log(np.linalg.det(cov_H0(p, x)))/2 \\\n",
    "                    - np.log(sigma) - 2 * np.log(2 * np.pi) - np.log(np.linalg.det(cov))/2\n",
    "      \n",
    "    return float(np.exp(log_good_fit_ratio(p, x, wt_mut, wt_mu_map, wt_sigma_map, \\\n",
    "                                     mut_mu_map, mut_sigma_map) \\\n",
    "                  + log_occam(p, x, wt_sigma_map, mut_sigma_map, cov)))\n",
    "\n",
    "o_r = odds_ratio(df, covariance, WTmuMAP, WTsigmaMAP, MUTmuMAP, MUTsigmaMAP)\n",
    "print(\"\"\"Odds ratio = {0:.4f}\"\"\".format(o_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odds_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c89260126632>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_fish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mpseudo_confidence_interval_ar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mpseudo_frequentist_lowCI_ar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpseudo_frequentist_highCI_ar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def sample_data(data):\n",
    "    \n",
    "    wt_fish = data[data[\"genotype\"]==\"wt\"]\n",
    "    mut_fish = data[data[\"genotype\"]==\"mut\"]\n",
    "\n",
    "    def new_gaussian_draw(mu, std, s):\n",
    "        \"\"\"\n",
    "        draw a sample of size s from a Gaussian distribution with mu = mu and \n",
    "        sigma = std\n",
    "        \"\"\"\n",
    "        return np.random.normal(mu, std, s)\n",
    "\n",
    "    new_wt_fish = wt_fish.drop('mean_rest_bout_length', axis=1)\n",
    "    new_wt_fish['mean_rest_bout_length'] = new_gaussian_draw(muWT, sigmaWT, 17)\n",
    "    new_mut_fish = mut_fish.drop('mean_rest_bout_length', axis=1)\n",
    "    new_mut_fish['mean_rest_bout_length'] = new_gaussian_draw(muMUT, sigmaMUT, 22)\n",
    "    new_fish = pd.concat((new_wt_fish, new_mut_fish), axis=0)\n",
    "    \n",
    "    return new_fish\n",
    "\n",
    "pseudo_confidence_interval_ar = np.empty(100)\n",
    "pseudo_frequentist_lowCI_ar = np.empty(100)\n",
    "pseudo_frequentist_highCI_ar = np.empty(100)\n",
    "pseudo_credible_interval_ar = np.empty(100)\n",
    "pseudo_bayesian_lowCI_ar = np.empty(100)\n",
    "pseudo_bayesian_highCI_ar = np.empty(100)\n",
    "pseudo_p_value_ar = np.empty(100)\n",
    "pseudo_odds_ratio_ar = np.empty(100)\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    #sample data \n",
    "    pseudo_fish_data = sample_data(df)\n",
    "        \n",
    "    #get estimates from part a\n",
    "    pseudo_muWT, pseudo_muMUT, pseudo_sigmaWT, pseudo_sigmaMUT = \\\n",
    "                                                get_estimates(pseudo_fish_data)\n",
    "    \n",
    "    #get frequentist estimate from part b\n",
    "    pseudo_frequentist_estimate, pseudo_confidence_interval, \\\n",
    "    pseudo_frequentist_lowCI, pseudo_frequentist_highCI = \\\n",
    "    get_frequentist_estimate(pseudo_muWT, pseudo_sigmaWT, \n",
    "                             pseudo_muMUT, pseudo_sigmaMUT, \n",
    "                             pseudo_fish_data)\n",
    "        \n",
    "    #get bayesian estimate from part c\n",
    "    pseudo_bayesian_estimate, pseudo_credible_interval, \\\n",
    "    pseudo_covariance, pseudo_WTmuMAP, pseudo_MUTmuMAP, pseudo_WTsigmaMAP, \\\n",
    "    pseudo_MUTsigmaMAP, pseudo_bayesian_lowCI, pseudo_bayesian_highCI  = \\\n",
    "    get_bayesian_estimate(pseudo_fish_data)\n",
    "        \n",
    "    #get p-value from part d\n",
    "    pseudo_p_value = final_p_value(pseudo_fish_data, 10000)\n",
    "    \n",
    "    #get odd ratios from part e\n",
    "    pseudo_odds_ratio = odds_ratio(pseudo_fish_data,\n",
    "                                   pseudo_covariance,\n",
    "                                   pseudo_WTmuMAP,\n",
    "                                   pseudo_WTsigmaMAP,\n",
    "                                   pseudo_MUTmuMAP,\n",
    "                                   pseudo_MUTsigmaMAP)\n",
    "        \n",
    "    #store all values in arrays\n",
    "    pseudo_confidence_interval_ar[i], pseudo_frequentist_lowCI_ar[i], \\\n",
    "    pseudo_frequentist_highCI_ar[i], pseudo_credible_interval_ar[i], \\\n",
    "    pseudo_bayesian_lowCI_ar[i], pseudo_bayesian_highCI_ar[i], \\\n",
    "    pseudo_p_value_ar[i], pseudo_odds_ratio_ar[i] = pseudo_confidence_interval, \\\n",
    "    pseudo_frequentist_lowCI, pseudo_frequentist_highCI, \\\n",
    "    pseudo_credible_interval, pseudo_bayesian_lowCI, \\\n",
    "    pseudo_bayesian_highCI, pseudo_p_value, pseudo_odds_ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
